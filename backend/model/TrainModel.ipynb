{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Give credit for code foundation here*"
      ],
      "metadata": {
        "id": "LSd5ead2Zhlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grab vocab list from Github\n",
        "This can be changed at a later time. All that matter is that the vocab names are directly from QuickDraw and that the size of the output layer reflects the number of items in the text file."
      ],
      "metadata": {
        "id": "5qgroJDcWxlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Capstone-Projects-2023-Fall/project-smartspeech/SS-105/backend/model/quickdraw-vocab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39PRXq4xWvc9",
        "outputId": "2e721133-3475-4a45-9306-682ff3754515"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-02 18:54:42--  https://raw.githubusercontent.com/Capstone-Projects-2023-Fall/project-smartspeech/SS-105/backend/model/quickdraw-vocab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 272 [text/plain]\n",
            "Saving to: ‘quickdraw-vocab.txt’\n",
            "\n",
            "\rquickdraw-vocab.txt   0%[                    ]       0  --.-KB/s               \rquickdraw-vocab.txt 100%[===================>]     272  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-02 18:54:42 (7.61 MB/s) - ‘quickdraw-vocab.txt’ saved [272/272]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store class names into a list\n",
        "Remove newline characters and replace all spaces with underscores so that the data is equally represented."
      ],
      "metadata": {
        "id": "XZKXEBhLY0oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('quickdraw-vocab.txt', 'r')\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "MDrz9EV9W6J8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [c.replace('\\n', '').replace(' ', '_') for c in classes]"
      ],
      "metadata": {
        "id": "MiSI-lbGYzag"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data from Google\n"
      ],
      "metadata": {
        "id": "tRkg-S2baycE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "LNW-3nDka1_d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "metadata": {
        "id": "dc1eCTqwa_eY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwep-s15bHZF",
        "outputId": "0d973ff5-783e-43f1-dcb7-2486f951908e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/blueberry.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/carrot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diamond.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/foot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fork.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hamburger.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hand.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hospital.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paintbrush.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shoe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stairs.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toilet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/underwear.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "vXiTg7I3_zvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "G48V2KwvbIH4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "qmKGvnswAnPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables\n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file\n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "\n",
        "    #randomize the dataset\n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing\n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "metadata": {
        "id": "siEBq5hj_2xT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "metadata": {
        "id": "piq8ZBntAxtB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq86HewgBqiO",
        "outputId": "bd07ac29-4ea2-4291-e8ec-196f6ae5d7bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess data"
      ],
      "metadata": {
        "id": "_g4QLymFFUsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "_r_kbUTxBq9Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define model"
      ],
      "metadata": {
        "id": "Ykyf4Pj7FjBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='tanh'))\n",
        "model.add(layers.Dense(40, activation='softmax'))\n",
        "# Train model\n",
        "adam = tf.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPtNeLWmFd_P",
        "outputId": "0ad1244e-3d95-42a2-cd19-cba6e84aa09c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 14, 14, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 7, 7, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 7, 7, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 3, 3, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               73856     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 40)                5160      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102312 (399.66 KB)\n",
            "Trainable params: 102312 (399.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "7FNrJqbUG_2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-dMHAr5GxZ3",
        "outputId": "2b3115c8-0ecf-45dc-b295-5c8e0f9705cc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "450/450 - 4s - loss: 1.4114 - top_k_categorical_accuracy: 0.8604 - val_loss: 0.9265 - val_top_k_categorical_accuracy: 0.9259 - 4s/epoch - 8ms/step\n",
            "Epoch 2/5\n",
            "450/450 - 2s - loss: 0.8226 - top_k_categorical_accuracy: 0.9388 - val_loss: 0.7431 - val_top_k_categorical_accuracy: 0.9451 - 2s/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "450/450 - 2s - loss: 0.6980 - top_k_categorical_accuracy: 0.9495 - val_loss: 0.6876 - val_top_k_categorical_accuracy: 0.9480 - 2s/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "450/450 - 3s - loss: 0.6292 - top_k_categorical_accuracy: 0.9547 - val_loss: 0.6521 - val_top_k_categorical_accuracy: 0.9526 - 3s/epoch - 6ms/step\n",
            "Epoch 5/5\n",
            "450/450 - 2s - loss: 0.5801 - top_k_categorical_accuracy: 0.9591 - val_loss: 0.6071 - val_top_k_categorical_accuracy: 0.9555 - 2s/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a71f014df00>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ],
      "metadata": {
        "id": "pYo8ai8FH4FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry_8sp_HHZ5x",
        "outputId": "e0f85482-063b-41e9-a7df-df9fc25fc2e8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuarcy: 95.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store classes"
      ],
      "metadata": {
        "id": "oWo0ob_qIprf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "metadata": {
        "id": "lHHyiNj7H6u6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export weights and relevant files"
      ],
      "metadata": {
        "id": "ZLmYBgTDJhPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xaU_-7zPIuJs",
        "outputId": "9c6f64e0-9279-4cfe-b97d-733bfafa6f3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.14.0-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/89.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.7.5)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (6.1.1)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.20)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.14.0)\n",
            "Collecting tensorflow-decision-forests>=1.5.0 (from tensorflowjs)\n",
            "  Downloading tensorflow_decision_forests-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.15.0)\n",
            "Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (23.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.23.5)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.4.3)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (1.11.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (16.0.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.14.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (1.5.3)\n",
            "Collecting tensorflow<3,>=2.13.0 (from tensorflowjs)\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.42.0)\n",
            "Collecting wurlitzer (from tensorflow-decision-forests>=1.5.0->tensorflowjs)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<3,>=2.13.0->tensorflowjs)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<3,>=2.13.0->tensorflowjs)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow<3,>=2.13.0->tensorflowjs)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.16.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.5.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2023.3.post1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax>=0.7.2->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax>=0.7.2->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2023.6.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.17.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: wurlitzer, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-decision-forests-1.8.1 tensorflow-estimator-2.15.0 tensorflowjs-4.14.0 wurlitzer-3.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('keras.h5')"
      ],
      "metadata": {
        "id": "PMt-eOYdJm9q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q48zf5_7LWQu",
        "outputId": "31931fbd-8c36-4714-e9e2-5a45f5690dd9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-02 19:18:54.376670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-02 19:18:54.376727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-02 19:18:54.378383: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-02 19:18:55.399824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "metadata": {
        "id": "Pt5pc4SPLZoB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8osAbvDLezi",
        "outputId": "b825febb-99d1-411f-cd72-f978a066fe53"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/group1-shard1of1.bin (deflated 7%)\n",
            "  adding: model/class_names.txt (deflated 36%)\n",
            "  adding: model/model.json (deflated 82%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SXyr-SETLhjX",
        "outputId": "7f4d7e5d-0cfa-4092-8a69-ec4217c7f7e3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6dd5cc18-455d-4f5d-a390-f0468abc0a1c\", \"model.zip\", 380701)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lVt3ndW8LtZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}