{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSd5ead2Zhlc"
      },
      "source": [
        "*Give credit for code foundation here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qgroJDcWxlM"
      },
      "source": [
        "### Grab vocab list from Github\n",
        "This can be changed at a later time. All that matter is that the vocab names are directly from QuickDraw and that the size of the output layer reflects the number of items in the text file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39PRXq4xWvc9",
        "outputId": "461d38d3-cce5-49bb-d7c5-fb43487efb7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-10 19:56:50--  https://raw.githubusercontent.com/Capstone-Projects-2023-Fall/project-smartspeech/SS-121-122/backend/model/quickdraw-vocab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 391 [text/plain]\n",
            "Saving to: ‘quickdraw-vocab.txt’\n",
            "\n",
            "quickdraw-vocab.txt 100%[===================>]     391  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-10 19:56:51 (9.39 MB/s) - ‘quickdraw-vocab.txt’ saved [391/391]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Capstone-Projects-2023-Fall/project-smartspeech/SS-121-122/backend/model/quickdraw-vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZKXEBhLY0oh"
      },
      "source": [
        "### Store class names into a list\n",
        "Remove newline characters and replace all spaces with underscores so that the data is equally represented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDrz9EV9W6J8"
      },
      "outputs": [],
      "source": [
        "f = open('quickdraw-vocab.txt', 'r')\n",
        "classes = f.readlines()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiSI-lbGYzag"
      },
      "outputs": [],
      "source": [
        "classes = [c.replace('\\n', '').replace(' ', '_') for c in classes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRkg-S2baycE"
      },
      "source": [
        "### Download data from Google\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNW-3nDka1_d"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc1eCTqwa_eY"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwep-s15bHZF",
        "outputId": "a215e5a0-3869-4f05-9878-9af4dd0b50d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bandage.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bee.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/blueberry.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bowtie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/carrot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crown.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diamond.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/finger.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fish.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/foot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fork.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hamburger.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hand.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hospital.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shoe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/strawberry.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/underwear.npy\n"
          ]
        }
      ],
      "source": [
        "download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXiTg7I3_zvv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G48V2KwvbIH4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKGvnswAnPU"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "siEBq5hj_2xT"
      },
      "outputs": [],
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables\n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file\n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "\n",
        "    #randomize the dataset\n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing\n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "piq8ZBntAxtB"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq86HewgBqiO",
        "outputId": "71b14eb0-dea1-4344-8361-a209fb32f7c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172800\n"
          ]
        }
      ],
      "source": [
        "print(len(x_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g4QLymFFUsd"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_r_kbUTxBq9Q"
      },
      "outputs": [],
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykyf4Pj7FjBs"
      },
      "source": [
        "### Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPtNeLWmFd_P",
        "outputId": "474c2c05-f635-43dc-e8e3-156964c3383b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 14, 14, 16)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 7, 7, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 7, 7, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 3, 3, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               73856     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 54)                6966      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104118 (406.71 KB)\n",
            "Trainable params: 104118 (406.71 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='tanh'))\n",
        "model.add(layers.Dense(54, activation='softmax'))\n",
        "# Train model\n",
        "adam = tf.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FNrJqbUG_2W"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-dMHAr5GxZ3",
        "outputId": "97199ba6-2524-44c1-e47e-eac204bc938e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "608/608 - 6s - loss: 1.4308 - top_k_categorical_accuracy: 0.8534 - val_loss: 0.9240 - val_top_k_categorical_accuracy: 0.9264 - 6s/epoch - 10ms/step\n",
            "Epoch 2/5\n",
            "608/608 - 4s - loss: 0.8041 - top_k_categorical_accuracy: 0.9375 - val_loss: 0.7644 - val_top_k_categorical_accuracy: 0.9387 - 4s/epoch - 6ms/step\n",
            "Epoch 3/5\n",
            "608/608 - 3s - loss: 0.6834 - top_k_categorical_accuracy: 0.9477 - val_loss: 0.6962 - val_top_k_categorical_accuracy: 0.9456 - 3s/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "608/608 - 3s - loss: 0.6147 - top_k_categorical_accuracy: 0.9533 - val_loss: 0.6596 - val_top_k_categorical_accuracy: 0.9472 - 3s/epoch - 6ms/step\n",
            "Epoch 5/5\n",
            "608/608 - 4s - loss: 0.5685 - top_k_categorical_accuracy: 0.9571 - val_loss: 0.6336 - val_top_k_categorical_accuracy: 0.9491 - 4s/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7be287167d60>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYo8ai8FH4FH"
      },
      "source": [
        "### Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry_8sp_HHZ5x",
        "outputId": "4864ffb0-094a-43fe-8ba3-1de4fd4065c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuarcy: 95.30%\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWo0ob_qIprf"
      },
      "source": [
        "### Store classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lHHyiNj7H6u6"
      },
      "outputs": [],
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLmYBgTDJhPw"
      },
      "source": [
        "### Export weights and relevant files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaU_-7zPIuJs",
        "outputId": "81d03bfa-401a-4ebb-f3a6-9459ab22d735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.7.5)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (6.1.1)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.20)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.15.0.post1)\n",
            "Requirement already satisfied: tensorflow-decision-forests>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.15.0)\n",
            "Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (23.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.23.5)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.4.3)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (1.11.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (16.0.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (1.5.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.42.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.16.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.1)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PMt-eOYdJm9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3b5abd-0f9d-448d-a845-e138cad32481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('keras.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q48zf5_7LWQu",
        "outputId": "d0dd71b1-7721-4db9-e17a-0f6514f33501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "2023-12-10 20:35:57.797800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 20:35:57.797905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 20:35:57.961676: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 20:36:00.644742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Pt5pc4SPLZoB"
      },
      "outputs": [],
      "source": [
        "\n",
        "!cp class_names.txt model/class_names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8osAbvDLezi",
        "outputId": "456b6fa9-8d32-4ba6-cc4d-a42af5c44fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/group1-shard1of1.bin (deflated 7%)\n",
            "  adding: model/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: model/model.json (deflated 82%)\n",
            "  adding: model/class_names.txt (deflated 38%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r model.zip model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SXyr-SETLhjX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "56001102-90d7-4080-8ffb-b55f57a1b48f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f59691b4-ff31-4a6d-b55d-799364fab5d7\", \"model.zip\", 387972)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2lXufrxBKrw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVt3ndW8LtZY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}